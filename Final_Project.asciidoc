#

Top venues around NYC’s universities

== Business Problem

The idea from this project is to help who want to gain benefits from the
trending venues around to the universities of the New York City such as
student’s services stores owners who want to open their stores near to
places visible and known by providing a clear understanding of the
trending places around the top universities and academies in New York
City and clustering them based on their common characteristics and that
will help them in making their decision.

== Interest

The targeted audience of this project are those who want to make a
business targeting the students, such as students’ services stores,
coffee shops dedicated to the study and so on, and want to open their
business in places known and visible by the students and obtain a
competitive advantage.

== Data acquisition

Firstly, I use data of the universities and academies in New York City
that contain a lot of information about them such as their names,
longitude, latitude, zip code and so on from Homeland Infrastructure
Foundation-Level Data (HIFLD), but from this dataset, I will need just
the university name and latitude and longitude so, I will drop the other
columns

Secondly, I will use the Foursquare Website to extract the trending
venues around the 30 from the universities and academies with the help
of the previously modified dataset of New York universities

== Importing the required libraries


+*In[44]:*+
[source, ipython3]
----
import pandas as pd # library for data analsysis
import requests # library to handle requests
import numpy as np # library to handle data in a vectorized manner
import random # library for random number generation

!conda install -c conda-forge geopy --yes 
from geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values

# libraries for displaying images
from IPython.display import Image 
from IPython.core.display import HTML 
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as colors

# tranforming json file into a pandas dataframe library
from pandas.io.json import json_normalize

# for clustering
from sklearn.cluster import KMeans
!conda install -c conda-forge folium=0.5.0 --yes
import folium # plotting library

print('Folium installed')
print('Libraries imported.')
----


+*Out[44]:*+
----
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.5.11
  latest version: 4.8.2

Please update conda by running

    $ conda update -n base -c defaults conda



# All requested packages already installed.

Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.5.11
  latest version: 4.8.2

Please update conda by running

    $ conda update -n base -c defaults conda



# All requested packages already installed.

Folium installed
Libraries imported.
----

== Importing and cleaning the universities data


+*In[45]:*+
[source, ipython3]
----
us_uni=pd.read_csv('Colleges_and_Universities.csv')
----


+*In[46]:*+
[source, ipython3]
----
NY_uni=pd.DataFrame(us_uni[us_uni["CITY"]=="NEW YORK"])
NY_uni.head()
----


+*Out[46]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |X |Y |OBJECTID |IPEDSID |NAME |ADDRESS |CITY |STATE |ZIP |ZIP4 |...
|ALIAS |SIZE_SET |INST_SIZE |PT_ENROLL |FT_ENROLL |TOT_ENROLL |HOUSING
|DORM_CAP |TOT_EMP |SHELTER_ID
|5 |-73.991271 |40.713812 |7006 |193070 |MESIVTHA TIFERETH JERUSALEM OF
AMERICA |145 E BROADWAY |NEW YORK |NY |10002 |6301 |... |NOT AVAILABLE
|6 |1 |-999 |69 |69 |1 |146 |12 |NOT AVAILABLE

|282 |-73.980278 |40.751893 |133 |447430 |CARSTEN INSTITUTE OF
COSMETOLOGY |290 MADISON AVENUE 5TH FLOOR |NEW YORK |NY |10017 |NOT
AVAILABLE |... |NOT AVAILABLE |-2 |1 |53 |41 |94 |2 |-999 |14 |NOT
AVAILABLE

|458 |-73.987638 |40.772309 |309 |188854 |AMERICAN MUSICAL AND DRAMATIC
ACADEMY |211 WEST 61ST STREET |NEW YORK |NY |10023 |NOT AVAILABLE |...
|NOT AVAILABLE |11 |2 |-999 |1515 |1515 |1 |941 |447 |NOT AVAILABLE

|459 |-73.979434 |40.753993 |310 |189228 |BERKELEY COLLEGE-NEW YORK |3
EAST 43 STREET |NEW YORK |NY |10017 |NOT AVAILABLE |... |BERKELEY
COLLEGE NYC CAMPUS | BERKELEY COLLEGE... |12 |2 |876 |2759 |3635 |2
|-999 |520 |NOT AVAILABLE

|463 |-73.973595 |40.750855 |314 |190035 |CUNY SYSTEM OFFICE |205 EAST
42ND STREET |NEW YORK |NY |10017 |NOT AVAILABLE |... |CUNY CENTRAL
OFFICE | CUNY CENTRAL | THE CITY ... |-2 |-2 |-999 |-999 |-999 |-2 |-999
|1184 |NOT AVAILABLE
|===

5 rows × 45 columns
----


+*In[47]:*+
[source, ipython3]
----
NY_uni.shape
----


+*Out[47]:*+
----(86, 45)----


+*In[48]:*+
[source, ipython3]
----
NY_uni.columns
----


+*Out[48]:*+
----Index(['X', 'Y', 'OBJECTID', 'IPEDSID', 'NAME', 'ADDRESS', 'CITY', 'STATE',
       'ZIP', 'ZIP4', 'TELEPHONE', 'TYPE', 'STATUS', 'POPULATION', 'COUNTY',
       'COUNTYFIPS', 'COUNTRY', 'LATITUDE', 'LONGITUDE', 'NAICS_CODE',
       'NAICS_DESC', 'SOURCE', 'SOURCEDATE', 'VAL_METHOD', 'VAL_DATE',
       'WEBSITE', 'STFIPS', 'COFIPS', 'SECTOR', 'LEVEL_', 'HI_OFFER',
       'DEG_GRANT', 'LOCALE', 'CLOSE_DATE', 'MERGE_ID', 'ALIAS', 'SIZE_SET',
       'INST_SIZE', 'PT_ENROLL', 'FT_ENROLL', 'TOT_ENROLL', 'HOUSING',
       'DORM_CAP', 'TOT_EMP', 'SHELTER_ID'],
      dtype='object')----


+*In[49]:*+
[source, ipython3]
----
NY_uni.drop(columns=['X','OBJECTID', 'IPEDSID','Y','ADDRESS', 'CITY', 'STATE',
       'ZIP', 'ZIP4', 'TELEPHONE', 'TYPE', 'STATUS', 'POPULATION', 'COUNTY',
       'COUNTYFIPS', 'COUNTRY','NAICS_CODE',
       'NAICS_DESC', 'SOURCE', 'SOURCEDATE', 'VAL_METHOD', 'VAL_DATE',
       'WEBSITE', 'STFIPS', 'COFIPS', 'SECTOR', 'LEVEL_', 'HI_OFFER',
       'DEG_GRANT', 'LOCALE', 'CLOSE_DATE', 'MERGE_ID', 'ALIAS', 'SIZE_SET',
       'INST_SIZE', 'PT_ENROLL', 'FT_ENROLL', 'TOT_ENROLL', 'HOUSING',
       'DORM_CAP', 'TOT_EMP', 'SHELTER_ID'],inplace=True)
NY_uni.head()
----


+*Out[49]:*+
----
[cols=",,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE
|5 |MESIVTHA TIFERETH JERUSALEM OF AMERICA |40.713812 |-73.991271
|282 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278
|458 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638
|459 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434
|463 |CUNY SYSTEM OFFICE |40.750855 |-73.973595
|===
----


+*In[50]:*+
[source, ipython3]
----
NY_uni.reset_index(drop=True,inplace=True)
NY_uni.head(57)
----


+*Out[50]:*+
----
[cols=",,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE
|0 |MESIVTHA TIFERETH JERUSALEM OF AMERICA |40.713812 |-73.991271

|1 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278

|2 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638

|3 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434

|4 |CUNY SYSTEM OFFICE |40.750855 |-73.973595

|5 |METROPOLITAN COLLEGE OF NEW YORK |40.708592 |-74.014677

|6 |HELENE FULD COLLEGE OF NURSING |40.802476 |-73.943325

|7 |LIM COLLEGE |40.759786 |-73.975317

|8 |MARYMOUNT MANHATTAN COLLEGE |40.768723 |-73.959790

|9 |THE NEW SCHOOL |40.735498 |-73.997158

|10 |TOURO COLLEGE |40.753362 |-73.989488

|11 |PACIFIC COLLEGE OF ORIENTAL MEDICINE-NEW YORK |40.708899
|-74.006629

|12 |THE KING'S COLLEGE |40.706558 |-74.012296

|13 |MANHATTAN INSTITUTE |40.754262 |-73.977344

|14 |INSTITUTE OF CULINARY EDUCATION |40.712988 |-74.015157

|15 |FOCUS PERSONAL TRAINING INSTITUTE |40.745880 |-73.991781

|16 |NEW YORK LAW SCHOOL |40.717762 |-74.006894

|17 |THE ART INSTITUTE OF NEW YORK CITY |40.755042 |-73.989177

|18 |NEW AGE TRAINING |40.748278 |-73.991510

|19 |THE JUILLIARD SCHOOL |40.773725 |-73.982913

|20 |THE AILEY SCHOOL |40.766921 |-73.986891

|21 |CUNY BERNARD M BARUCH COLLEGE |40.740238 |-73.983417

|22 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |40.764351 |-73.983749

|23 |EMPIRE BEAUTY SCHOOL-MANHATTAN |40.748938 |-73.986453

|24 |TEACHERS COLLEGE AT COLUMBIA UNIVERSITY |40.810311 |-73.960399

|25 |PACE UNIVERSITY-NEW YORK |40.711710 |-74.004874

|26 |YESHIVA UNIVERSITY |40.850800 |-73.928541

|27 |SOTHEBY'S INSTITUTE OF ART-NY |40.756399 |-73.972588

|28 |AMERICAN ACADEMY OF PERSONAL TRAINING |40.722342 |-74.002465

|29 |ARROJO COSMETOLOGY SCHOOL |40.727565 |-74.005162

|30 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |40.744988
|-73.986557

|31 |RELAY GRADUATE SCHOOL OF EDUCATION |40.740509 |-73.993411

|32 |DEVRY COLLEGE OF NEW YORK |40.747654 |-73.983468

|33 |CULINARY TECH CENTER |40.754175 |-73.998972

|34 |MILDRED ELLEY-NEW YORK CAMPUS |40.705781 |-74.014004

|35 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |40.742987 |-73.984860

|36 |CUNY HUNTER COLLEGE |40.768669 |-73.964795

|37 |TRI-STATE COLLEGE OF ACUPUNCTURE |40.739862 |-74.002085

|38 |AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNER... |40.769031
|-73.993782

|39 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |40.751351 |-73.980647

|40 |NEW YORK UNIVERSITY |40.729452 |-73.997264

|41 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384
|-73.995670

|42 |NEW YORK ACADEMY OF ART |40.718388 |-74.006019

|43 |JOFFREY BALLET SCHOOL |40.734545 |-73.998566

|44 |BANK STREET COLLEGE OF EDUCATION |40.805604 |-73.966643

|45 |COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AN... |40.729380
|-73.990516

|46 |CUNY JOHN JAY COLLEGE OF CRIMINAL JUSTICE |40.770346 |-73.988403

|47 |THE GENERAL THEOLOGICAL SEMINARY |40.745558 |-74.003767

|48 |JEWISH THEOLOGICAL SEMINARY OF AMERICA |40.811959 |-73.960287

|49 |NEW YORK CONSERVATORY FOR DRAMATIC ARTS |40.740148 |-73.993388

|50 |LIA SCHORR INSTITUTE OF COSMETIC SKIN CARE TRA... |40.760598
|-73.969644

|51 |COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK |40.808286 |-73.961885

|52 |BARNARD COLLEGE |40.809137 |-73.964027

|53 |CIRCLE IN THE SQUARE THEATRE SCHOOL |40.762059 |-73.984607

|54 |CUNY GRADUATE SCHOOL AND UNIVERSITY CENTER |40.748503 |-73.983575

|55 |FASHION INSTITUTE OF TECHNOLOGY |40.747310 |-73.994781

|56 |THE INTERNATIONAL CULINARY CENTER |40.720817 |-74.000090
|===
----


+*In[75]:*+
[source, ipython3]
----
CLIENT_ID = '####################################################' # Foursquare ID
CLIENT_SECRET = '##########################################' # Foursquare Secret
VERSION = '20180604'
LIMIT = 50
RADIUS= 2000
print('Your credentails:')
print('CLIENT_ID: ' + CLIENT_ID)
print('CLIENT_SECRET:' + CLIENT_SECRET)
----


+*Out[75]:*+
----
Your credentails:
CLIENT_ID: ####################################################
CLIENT_SECRET:##########################################
----

== Creating a map of NYC’s universities


+*In[52]:*+
[source, ipython3]
----
address = '102 North End Ave, New York, NY'

geolocator = Nominatim(user_agent="foursquare_agent")
location = geolocator.geocode(address)
latitude = location.latitude
longitude = location.longitude
print(latitude, longitude)
----


+*Out[52]:*+
----
40.7149555 -74.0153365
----


+*In[53]:*+
[source, ipython3]
----
# create map of New York using latitude and longitude values
map_newyork = folium.Map(location=[latitude, longitude], zoom_start=10)

# add markers to map
for lat, lng, name in zip(NY_uni['LATITUDE'], NY_uni['LONGITUDE'], NY_uni['NAME']):
    label = '{}'.format(name)
    label = folium.Popup(label, parse_html=True)
    folium.CircleMarker(
        [lat, lng],
        radius=5,
        popup=label,
        color='blue',
        fill=True,
        fill_color='#3186cc',
        fill_opacity=0.7,
        parse_html=False).add_to(map_newyork)  
    
map_newyork
----


+*Out[53]:*+
----

----

== Getting the trending venues arounf each university

== CARSTEN INSTITUTE OF COSMETOLOGY


+*In[54]:*+
[source, ipython3]
----
def get_category_type(row):
    try:
        categories_list = row['categories']
    except:
        categories_list = row['venue.categories']
        
    if len(categories_list) == 0:
        return None
    else:
        return categories_list[0]['name']
----


+*In[14]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][1],NY_uni['LONGITUDE'][1], VERSION, RADIUS, LIMIT)

    #url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}'.format(CLIENT_ID, CLIENT_SECRET,, VERSION)
    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        carsten_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        carsten_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[15]:*+
[source, ipython3]
----
carsten_df
----


+*Out[15]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1118 |New York |10001 |NY
|United States |40.750537 |-73.993422
|===
----


+*In[17]:*+
[source, ipython3]
----
df=pd.DataFrame()
df=df.append([NY_uni[1:2]]*4,ignore_index=True)
df=df.join(carsten_df [['name','categories','location.lat','location.lng']])
df
----


+*Out[17]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |New York
Penn Station |Train Station |40.750356 |-73.992510

|1 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |Grand
Central Terminal |Train Station |40.752774 |-73.977180

|2 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |Port
Authority Bus Terminal |Bus Station |40.757112 |-73.991597

|3 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |Times
Square |Plaza |40.758001 |-73.985588
|===
----

== AMERICAN MUSICAL AND DRAMATIC ACADEMY


+*In[20]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][2],NY_uni['LONGITUDE'][2], VERSION, RADIUS, LIMIT)

    #url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}'.format(CLIENT_ID, CLIENT_SECRET,, VERSION)
    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        musical_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        musical_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[21]:*+
[source, ipython3]
----
musical_df
----


+*Out[21]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |Manhattan Neighborhood Network |TV Station |182 |New York |10019 |NY
|United States |40.771220 |-73.989250

|1 |Times Square |Plaza |1602 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[152]:*+
[source, ipython3]
----
df1=pd.DataFrame()
df1=df1.append([NY_uni[2:3]]*2,ignore_index=True)
df1=df1.join(musical_df [['name','categories','location.lat','location.lng']])
df1
----


+*Out[152]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638
|Manhattan Neighborhood Network |TV Station |40.771220 |-73.989250

|1 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638 |Times
Square |Plaza |40.758001 |-73.985588
|===
----

== BERKELEY COLLEGE-NEW YORK


+*In[23]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][3],NY_uni['LONGITUDE'][3], VERSION, RADIUS, LIMIT)

    #url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}'.format(CLIENT_ID, CLIENT_SECRET,, VERSION)
    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        berkeley_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        berkeley_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[24]:*+
[source, ipython3]
----
berkeley_df
----


+*Out[24]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1174 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |233 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |684 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[153]:*+
[source, ipython3]
----
df2=pd.DataFrame()
df2=df2.append([NY_uni[3:4]]*3,ignore_index=True)
df2=df2.join(berkeley_df [['name','categories','location.lat','location.lng']])
df2
----


+*Out[153]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434 |New York Penn
Station |Train Station |40.750356 |-73.992510

|1 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434 |Grand Central
Terminal |Train Station |40.752774 |-73.977180

|2 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434 |Times Square
|Plaza |40.758001 |-73.985588
|===
----

== CUNY SYSTEM OFFICE


+*In[27]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][4],NY_uni['LONGITUDE'][4], VERSION, RADIUS, LIMIT)

    #url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}'.format(CLIENT_ID, CLIENT_SECRET,, VERSION)
    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        cunyoff_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        cunyoff_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[28]:*+
[source, ipython3]
----
cunyoff_df
----


+*Out[28]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1596 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |370 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1286 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[154]:*+
[source, ipython3]
----
df3=pd.DataFrame()
df3=df3.append([NY_uni[4:5]]*3,ignore_index=True)
df3=df3.join(cunyoff_df [['name','categories','location.lat','location.lng']])
df3
----


+*Out[154]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CUNY SYSTEM OFFICE |40.750855 |-73.973595 |New York Penn Station
|Train Station |40.750356 |-73.992510

|1 |CUNY SYSTEM OFFICE |40.750855 |-73.973595 |Grand Central Terminal
|Train Station |40.752774 |-73.977180

|2 |CUNY SYSTEM OFFICE |40.750855 |-73.973595 |Times Square |Plaza
|40.758001 |-73.985588
|===
----

== LIM COLLEGE


+*In[36]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][7],NY_uni['LONGITUDE'][7], VERSION, RADIUS, LIMIT)
    
    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        lim_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        lim_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)

----


+*In[37]:*+
[source, ipython3]
----
# display trending venues
lim_df
----


+*Out[37]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1789 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |796 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Manhattan Neighborhood Network |TV Station |1732 |New York |10019
|NY |United States |40.771220 |-73.989250

|3 |Times Square |Plaza |888 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[38]:*+
[source, ipython3]
----
df4=pd.DataFrame()
df4=df4.append([NY_uni[7:8]]*4,ignore_index=True)
df4=df4.join(lim_df[['name','categories','location.lat','location.lng']])
df4.head()
----


+*Out[38]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |LIM COLLEGE |40.759786 |-73.975317 |New York Penn Station |Train
Station |40.750356 |-73.992510

|1 |LIM COLLEGE |40.759786 |-73.975317 |Grand Central Terminal |Train
Station |40.752774 |-73.977180

|2 |LIM COLLEGE |40.759786 |-73.975317 |Manhattan Neighborhood Network
|TV Station |40.771220 |-73.989250

|3 |LIM COLLEGE |40.759786 |-73.975317 |Times Square |Plaza |40.758001
|-73.985588
|===
----

== THE NEW SCHOOL


+*In[43]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][9],NY_uni['LONGITUDE'][9], VERSION, RADIUS, LIMIT)
    
    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        news_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        news_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[44]:*+
[source, ipython3]
----
news_df
----


+*Out[44]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1699 |New York |10001 |NY
|United States |40.750356 |-73.99251
|===
----


+*In[155]:*+
[source, ipython3]
----
df5=pd.DataFrame()
df5=df5.append([NY_uni[9:10]]*1,ignore_index=True)
df5=df5.join(news_df[['name','categories','location.lat','location.lng']])
df5.head()
----


+*Out[155]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |THE NEW SCHOOL |40.735498 |-73.997158 |New York Penn Station |Train
Station |40.750356 |-73.99251
|===
----

== TOURO COLLEGE


+*In[47]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][10],NY_uni['LONGITUDE'][10], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        touro_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        touro_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[48]:*+
[source, ipython3]
----
touro_df
----


+*Out[48]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |420 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Times Square |Plaza |612 |New York |10036 |NY |United States
|40.758001 |-73.985588

|2 |Manhattan Neighborhood Network |TV Station |1988 |New York |10019
|NY |United States |40.771220 |-73.989250

|3 |Grand Central Terminal |Train Station |1039 |New York |10017 |NY
|United States |40.752774 |-73.977180
|===
----


+*In[49]:*+
[source, ipython3]
----
df6=pd.DataFrame()
df6=df6.append([NY_uni[10:11]]*4,ignore_index=True)
df6=df6.join(touro_df[['name','categories','location.lat','location.lng']])
df6
----


+*Out[49]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |TOURO COLLEGE |40.753362 |-73.989488 |New York Penn Station |Train
Station |40.750356 |-73.992510

|1 |TOURO COLLEGE |40.753362 |-73.989488 |Times Square |Plaza |40.758001
|-73.985588

|2 |TOURO COLLEGE |40.753362 |-73.989488 |Manhattan Neighborhood Network
|TV Station |40.771220 |-73.989250

|3 |TOURO COLLEGE |40.753362 |-73.989488 |Grand Central Terminal |Train
Station |40.752774 |-73.977180
|===
----

== MANHATTAN INSTITUTE


+*In[55]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][13],NY_uni['LONGITUDE'][13], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        manhattan_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        manhattan_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)

----


+*In[56]:*+
[source, ipython3]
----
manhattan_df
----


+*Out[56]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1350 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |166 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |810 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[58]:*+
[source, ipython3]
----
df7=pd.DataFrame()
df7=df7.append([NY_uni[13:14]]*3,ignore_index=True)
df7=df7.join(manhattan_df[['name','categories','location.lat','location.lng']])
df7
----


+*Out[58]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |MANHATTAN INSTITUTE |40.754262 |-73.977344 |New York Penn Station
|Train Station |40.750356 |-73.992510

|1 |MANHATTAN INSTITUTE |40.754262 |-73.977344 |Grand Central Terminal
|Train Station |40.752774 |-73.977180

|2 |MANHATTAN INSTITUTE |40.754262 |-73.977344 |Times Square |Plaza
|40.758001 |-73.985588
|===
----

== INSTITUTE OF CULINARY EDUCATION


+*In[63]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][14],NY_uni['LONGITUDE'][14], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        culinary_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        culinary_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)

----


+*In[64]:*+
[source, ipython3]
----
culinary_df
----


+*Out[64]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1350 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |166 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |810 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[156]:*+
[source, ipython3]
----
df8=pd.DataFrame()
df8=df8.append([NY_uni[14:15]]*3,ignore_index=True)
df8=df8.join(culinary_df[['name','categories','location.lat','location.lng']])
df8
----


+*Out[156]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |INSTITUTE OF CULINARY EDUCATION |40.712988 |-74.015157 |New York
Penn Station |Train Station |40.750356 |-73.992510

|1 |INSTITUTE OF CULINARY EDUCATION |40.712988 |-74.015157 |Grand
Central Terminal |Train Station |40.752774 |-73.977180

|2 |INSTITUTE OF CULINARY EDUCATION |40.712988 |-74.015157 |Times Square
|Plaza |40.758001 |-73.985588
|===
----

== FOCUS PERSONAL TRAINING INSTITUTE


+*In[66]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][15],NY_uni['LONGITUDE'][15], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        focus_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        focus_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[67]:*+
[source, ipython3]
----
focus_df
----


+*Out[67]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |502 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1450 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1446 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[68]:*+
[source, ipython3]
----
df9=pd.DataFrame()
df9=df9.append([NY_uni[15:16]]*3,ignore_index=True)
df9=df9.join(focus_df[['name','categories','location.lat','location.lng']])
df9
----


+*Out[68]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |FOCUS PERSONAL TRAINING INSTITUTE |40.74588 |-73.991781 |New York
Penn Station |Train Station |40.750356 |-73.992510

|1 |FOCUS PERSONAL TRAINING INSTITUTE |40.74588 |-73.991781 |Grand
Central Terminal |Train Station |40.752774 |-73.977180

|2 |FOCUS PERSONAL TRAINING INSTITUTE |40.74588 |-73.991781 |Times
Square |Plaza |40.758001 |-73.985588
|===
----

== THE ART INSTITUTE OF NEW YORK CITY


+*In[71]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][17],NY_uni['LONGITUDE'][17], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        art_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        art_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[72]:*+
[source, ipython3]
----
art_df
----


+*Out[72]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |592 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Times Square |Plaza |447 |New York |10036 |NY |United States
|40.758001 |-73.985588

|2 |Grand Central Terminal |Train Station |1042 |New York |10017 |NY
|United States |40.752774 |-73.977180

|3 |Manhattan Neighborhood Network |TV Station |1800 |New York |10019
|NY |United States |40.771220 |-73.989250
|===
----


+*In[73]:*+
[source, ipython3]
----
df10=pd.DataFrame()
df10=df10.append([NY_uni[17:18]]*4,ignore_index=True)
df10=df10.join(art_df[['name','categories','location.lat','location.lng']])
df10
----


+*Out[73]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |THE ART INSTITUTE OF NEW YORK CITY |40.755042 |-73.989177 |New York
Penn Station |Train Station |40.750356 |-73.992510

|1 |THE ART INSTITUTE OF NEW YORK CITY |40.755042 |-73.989177 |Times
Square |Plaza |40.758001 |-73.985588

|2 |THE ART INSTITUTE OF NEW YORK CITY |40.755042 |-73.989177 |Grand
Central Terminal |Train Station |40.752774 |-73.977180

|3 |THE ART INSTITUTE OF NEW YORK CITY |40.755042 |-73.989177 |Manhattan
Neighborhood Network |TV Station |40.771220 |-73.989250
|===
----

== NEW AGE TRAINING


+*In[74]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][18],NY_uni['LONGITUDE'][18], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        new_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        new_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)

----


+*In[75]:*+
[source, ipython3]
----
new_df
----


+*Out[75]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |246 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Times Square |Plaza |1192 |New York |10036 |NY |United States
|40.758001 |-73.985588

|2 |Grand Central Terminal |Train Station |1307 |New York |10017 |NY
|United States |40.752774 |-73.977180
|===
----


+*In[76]:*+
[source, ipython3]
----
df11=pd.DataFrame()
df11=df11.append([NY_uni[18:19]]*3,ignore_index=True)
df11=df11.join(new_df[['name','categories','location.lat','location.lng']])
df11
----


+*Out[76]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |NEW AGE TRAINING |40.748278 |-73.99151 |New York Penn Station |Train
Station |40.750356 |-73.992510

|1 |NEW AGE TRAINING |40.748278 |-73.99151 |Times Square |Plaza
|40.758001 |-73.985588

|2 |NEW AGE TRAINING |40.748278 |-73.99151 |Grand Central Terminal
|Train Station |40.752774 |-73.977180
|===
----

== THE JUILLIARD SCHOOL


+*In[77]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][19],NY_uni['LONGITUDE'][19], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        juilliard_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        juilliard_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[78]:*+
[source, ipython3]
----
juilliard_df
----


+*Out[78]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |Times Square |Plaza |1764 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[157]:*+
[source, ipython3]
----
df12=pd.DataFrame()
df12=df12.append([NY_uni[19:20]]*1,ignore_index=True)
df12=df12.join(juilliard_df[['name','categories','location.lat','location.lng']])
df12
----


+*Out[157]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |THE JUILLIARD SCHOOL |40.773725 |-73.982913 |Times Square |Plaza
|40.758001 |-73.985588
|===
----

== THE AILEY SCHOOL


+*In[81]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][20],NY_uni['LONGITUDE'][20], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        ailey_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        ailey_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[82]:*+
[source, ipython3]
----
ailey_df
----


+*Out[82]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1903 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1774 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |998 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[158]:*+
[source, ipython3]
----
df13=pd.DataFrame()
df13=df13.append([NY_uni[20:21]]*3,ignore_index=True)
df13=df13.join(ailey_df[['name','categories','location.lat','location.lng']])
df13
----


+*Out[158]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |THE AILEY SCHOOL |40.766921 |-73.986891 |New York Penn Station
|Train Station |40.750356 |-73.992510

|1 |THE AILEY SCHOOL |40.766921 |-73.986891 |Grand Central Terminal
|Train Station |40.752774 |-73.977180

|2 |THE AILEY SCHOOL |40.766921 |-73.986891 |Times Square |Plaza
|40.758001 |-73.985588
|===
----

== CUNY BERNARD M BARUCH COLLEGE


+*In[85]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][21],NY_uni['LONGITUDE'][21], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        bernard_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        bernard_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[86]:*+
[source, ipython3]
----
bernard_df
----


+*Out[86]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1362 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1491 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1985 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[87]:*+
[source, ipython3]
----
df14=pd.DataFrame()
df14=df14.append([NY_uni[21:22]]*3,ignore_index=True)
df14=df14.join(bernard_df[['name','categories','location.lat','location.lng']])
df14
----


+*Out[87]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CUNY BERNARD M BARUCH COLLEGE |40.740238 |-73.983417 |New York Penn
Station |Train Station |40.750356 |-73.992510

|1 |CUNY BERNARD M BARUCH COLLEGE |40.740238 |-73.983417 |Grand Central
Terminal |Train Station |40.752774 |-73.977180

|2 |CUNY BERNARD M BARUCH COLLEGE |40.740238 |-73.983417 |Times Square
|Plaza |40.758001 |-73.985588
|===
----

== MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH


+*In[88]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][22],NY_uni['LONGITUDE'][22], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        mandl_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        mandl_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[89]:*+
[source, ipython3]
----
mandl_df
----


+*Out[89]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1724 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1402 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |723 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[159]:*+
[source, ipython3]
----
df15=pd.DataFrame()
df15=df15.append([NY_uni[22:23]]*3,ignore_index=True)
df15=df15.join(mandl_df[['name','categories','location.lat','location.lng']])
df15
----


+*Out[159]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |40.764351 |-73.983749
|New York Penn Station |Train Station |40.750356 |-73.992510

|1 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |40.764351 |-73.983749
|Grand Central Terminal |Train Station |40.752774 |-73.977180

|2 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |40.764351 |-73.983749
|Times Square |Plaza |40.758001 |-73.985588
|===
----

== EMPIRE BEAUTY SCHOOL-MANHATTAN


+*In[91]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][23],NY_uni['LONGITUDE'][23], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        empire_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        empire_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[92]:*+
[source, ipython3]
----
empire_df
----


+*Out[92]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |534 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |891 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1011 |New York |10036 |NY |United States
|40.758001 |-73.985588

|3 |Trader Joe's |Grocery Store |1005 |New York |10010 |NY |United
States |40.741739 |-73.993653
|===
----


+*In[160]:*+
[source, ipython3]
----
df16=pd.DataFrame()
df16=df16.append([NY_uni[23:24]]*4,ignore_index=True)
df16=df16.join(empire_df[['name','categories','location.lat','location.lng']])
df16.head()
----


+*Out[160]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |EMPIRE BEAUTY SCHOOL-MANHATTAN |40.748938 |-73.986453 |New York Penn
Station |Train Station |40.750356 |-73.992510

|1 |EMPIRE BEAUTY SCHOOL-MANHATTAN |40.748938 |-73.986453 |Grand Central
Terminal |Train Station |40.752774 |-73.977180

|2 |EMPIRE BEAUTY SCHOOL-MANHATTAN |40.748938 |-73.986453 |Times Square
|Plaza |40.758001 |-73.985588

|3 |EMPIRE BEAUTY SCHOOL-MANHATTAN |40.748938 |-73.986453 |Trader Joe's
|Grocery Store |40.741739 |-73.993653
|===
----

== SOTHEBY’S INSTITUTE OF ART-NY


+*In[100]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][27],NY_uni['LONGITUDE'][27], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        sotheby_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        sotheby_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[101]:*+
[source, ipython3]
----
sotheby_df
----


+*Out[101]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1809 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |559 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1110 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[161]:*+
[source, ipython3]
----
df17=pd.DataFrame()
df17=df17.append([NY_uni[27:28]]*3,ignore_index=True)
df17=df17.join(sotheby_df[['name','categories','location.lat','location.lng']])
df17.head()
----


+*Out[161]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |SOTHEBY'S INSTITUTE OF ART-NY |40.756399 |-73.972588 |New York Penn
Station |Train Station |40.750356 |-73.992510

|1 |SOTHEBY'S INSTITUTE OF ART-NY |40.756399 |-73.972588 |Grand Central
Terminal |Train Station |40.752774 |-73.977180

|2 |SOTHEBY'S INSTITUTE OF ART-NY |40.756399 |-73.972588 |Times Square
|Plaza |40.758001 |-73.985588
|===
----

== CHRISTINE VALMY INTERNATIONAL SCHOOL


+*In[109]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][30],NY_uni['LONGITUDE'][30], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        christine_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        christine_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[110]:*+
[source, ipython3]
----
christine_df
----


+*Out[110]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |780 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1173 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1450 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[162]:*+
[source, ipython3]
----
df18=pd.DataFrame()
df18=df18.append([NY_uni[30:31]]*3,ignore_index=True)
df18=df18.join(christine_df[['name','categories','location.lat','location.lng']])
df18.head()
----


+*Out[162]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |40.744988
|-73.986557 |New York Penn Station |Train Station |40.750356 |-73.992510

|1 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |40.744988
|-73.986557 |Grand Central Terminal |Train Station |40.752774
|-73.977180

|2 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |40.744988
|-73.986557 |Times Square |Plaza |40.758001 |-73.985588
|===
----

== RELAY GRADUATE SCHOOL OF EDUCATION


+*In[113]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][31],NY_uni['LONGITUDE'][31], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        relay_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        relay_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[114]:*+
[source, ipython3]
----
relay_df
----


+*Out[114]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1098 |New York |10001 |NY
|United States |40.750356 |-73.99251

|1 |Grand Central Terminal |Train Station |1933 |New York |10017 |NY
|United States |40.752774 |-73.97718
|===
----


+*In[163]:*+
[source, ipython3]
----
df19=pd.DataFrame()
df19=df19.append([NY_uni[31:32]]*2,ignore_index=True)
df19=df19.join(relay_df[['name','categories','location.lat','location.lng']])
df19.head()
----


+*Out[163]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |RELAY GRADUATE SCHOOL OF EDUCATION |40.740509 |-73.993411 |New York
Penn Station |Train Station |40.750356 |-73.99251

|1 |RELAY GRADUATE SCHOOL OF EDUCATION |40.740509 |-73.993411 |Grand
Central Terminal |Train Station |40.752774 |-73.97718
|===
----

== DEVRY COLLEGE OF NEW YORK


+*In[116]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][32],NY_uni['LONGITUDE'][32], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        devry_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        devry_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[117]:*+
[source, ipython3]
----
devry_df
----


+*Out[117]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |819 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |778 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1165 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[164]:*+
[source, ipython3]
----
df20=pd.DataFrame()
df20=df20.append([NY_uni[32:33]]*3,ignore_index=True)
df20=df20.join(devry_df[['name','categories','location.lat','location.lng']])
df20.head()
----


+*Out[164]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |DEVRY COLLEGE OF NEW YORK |40.747654 |-73.983468 |New York Penn
Station |Train Station |40.750356 |-73.992510

|1 |DEVRY COLLEGE OF NEW YORK |40.747654 |-73.983468 |Grand Central
Terminal |Train Station |40.752774 |-73.977180

|2 |DEVRY COLLEGE OF NEW YORK |40.747654 |-73.983468 |Times Square
|Plaza |40.758001 |-73.985588
|===
----

== CULINARY TECH CENTER


+*In[120]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][33],NY_uni['LONGITUDE'][33], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        cultech_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        cultech_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[121]:*+
[source, ipython3]
----
cultech_df
----


+*Out[121]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |Grand Central Terminal |Train Station |1844 |New York |10017 |NY
|United States |40.752774 |-73.977180

|1 |New York Penn Station |Train Station |691 |New York |10001 |NY
|United States |40.750356 |-73.992510

|2 |Times Square |Plaza |1206 |New York |10036 |NY |United States
|40.758001 |-73.985588

|3 |Google New York |Office |1458 |New York |10011 |NY |United States
|40.741616 |-74.003906
|===
----


+*In[165]:*+
[source, ipython3]
----
df21=pd.DataFrame()
df21=df21.append([NY_uni[33:34]]*4,ignore_index=True)
df21=df21.join(cultech_df[['name','categories','location.lat','location.lng']])
df21.head()
----


+*Out[165]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CULINARY TECH CENTER |40.754175 |-73.998972 |Grand Central Terminal
|Train Station |40.752774 |-73.977180

|1 |CULINARY TECH CENTER |40.754175 |-73.998972 |New York Penn Station
|Train Station |40.750356 |-73.992510

|2 |CULINARY TECH CENTER |40.754175 |-73.998972 |Times Square |Plaza
|40.758001 |-73.985588

|3 |CULINARY TECH CENTER |40.754175 |-73.998972 |Google New York |Office
|40.741616 |-74.003906
|===
----

== ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS


+*In[126]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][35],NY_uni['LONGITUDE'][35], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        atelier_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        atelier_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[127]:*+
[source, ipython3]
----
atelier_df
----


+*Out[127]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1043 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1267 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1672 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[166]:*+
[source, ipython3]
----
df22=pd.DataFrame()
df22=df22.append([NY_uni[35:36]]*3,ignore_index=True)
df22=df22.join(atelier_df[['name','categories','location.lat','location.lng']])
df22.head()
----


+*Out[166]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |40.742987 |-73.98486 |New
York Penn Station |Train Station |40.750356 |-73.992510

|1 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |40.742987 |-73.98486
|Grand Central Terminal |Train Station |40.752774 |-73.977180

|2 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |40.742987 |-73.98486
|Times Square |Plaza |40.758001 |-73.985588
|===
----

== CUNY HUNTER COLLEGE


+*In[129]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][36],NY_uni['LONGITUDE'][36], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        cunyh_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        cunyh_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[130]:*+
[source, ipython3]
----
cunyh_df
----


+*Out[130]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |Central Park |Park |1715 |New York |10028 |NY |United States
|40.784083 |-73.964853
|===
----


+*In[167]:*+
[source, ipython3]
----
df23=pd.DataFrame()
df23=df23.append([NY_uni[36:37]]*1,ignore_index=True)
df23=df23.join(cunyh_df[['name','categories','location.lat','location.lng']])
df23.head()
----


+*Out[167]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CUNY HUNTER COLLEGE |40.768669 |-73.964795 |Central Park |Park
|40.784083 |-73.964853
|===
----

== TRI-STATE COLLEGE OF ACUPUNCTURE


+*In[132]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][37],NY_uni['LONGITUDE'][37], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        tri_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        tri_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[133]:*+
[source, ipython3]
----
tri_df
----


+*Out[133]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1420 |New York |10001 |NY
|United States |40.750356 |-73.99251
|===
----


+*In[168]:*+
[source, ipython3]
----
df24=pd.DataFrame()
df24=df24.append([NY_uni[37:38]]*1,ignore_index=True)
df24=df24.join(tri_df[['name','categories','location.lat','location.lng']])
df24.head()
----


+*Out[168]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |TRI-STATE COLLEGE OF ACUPUNCTURE |40.739862 |-74.002085 |New York
Penn Station |Train Station |40.750356 |-73.99251
|===
----

== AMERICAN ACADEMY MCALLISTER INSTITUTE


+*In[135]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][38],NY_uni['LONGITUDE'][38], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        mcallister_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        mcallister_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[136]:*+
[source, ipython3]
----
mcallister_df
----


+*Out[136]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |Times Square |Plaza |1408 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[169]:*+
[source, ipython3]
----
df25=pd.DataFrame()
df25=df25.append([NY_uni[38:39]]*1,ignore_index=True)
df25=df25.join(mcallister_df[['name','categories','location.lat','location.lng']])
df25.head()
----


+*Out[169]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNER... |40.769031
|-73.993782 |Times Square |Plaza |40.758001 |-73.985588
|===
----

== GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK


+*In[138]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][39],NY_uni['LONGITUDE'][39], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        gemo_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        gemo_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[139]:*+
[source, ipython3]
----
gemo_df
----


+*Out[139]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1006 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |332 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |849 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[170]:*+
[source, ipython3]
----
df26=pd.DataFrame()
df26=df26.append([NY_uni[39:40]]*3,ignore_index=True)
df26=df26.join(gemo_df[['name','categories','location.lat','location.lng']])
df26.head()
----


+*Out[170]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |40.751351 |-73.980647
|New York Penn Station |Train Station |40.750356 |-73.992510

|1 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |40.751351 |-73.980647
|Grand Central Terminal |Train Station |40.752774 |-73.977180

|2 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |40.751351 |-73.980647
|Times Square |Plaza |40.758001 |-73.985588
|===
----

== NEW YORK UNIVERSITY


+*In[171]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][40],NY_uni['LONGITUDE'][40], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        NYU_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        NYU_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[172]:*+
[source, ipython3]
----
NYU_df
----


+*Out[172]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1006 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |332 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |849 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[173]:*+
[source, ipython3]
----
df27=pd.DataFrame()
df27=df27.append([NY_uni[40:41]]*3,ignore_index=True)
df27=df27.join(NYU_df[['name','categories','location.lat','location.lng']])
df27.head()
----


+*Out[173]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |NEW YORK UNIVERSITY |40.729452 |-73.997264 |New York Penn Station
|Train Station |40.750356 |-73.992510

|1 |NEW YORK UNIVERSITY |40.729452 |-73.997264 |Grand Central Terminal
|Train Station |40.752774 |-73.977180

|2 |NEW YORK UNIVERSITY |40.729452 |-73.997264 |Times Square |Plaza
|40.758001 |-73.985588
|===
----

== SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES


+*In[144]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][41],NY_uni['LONGITUDE'][41], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        swedish_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        swedish_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[145]:*+
[source, ipython3]
----
swedish_df
----


+*Out[145]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |516 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Grand Central Terminal |Train Station |1713 |New York |10017 |NY
|United States |40.752774 |-73.977180

|2 |Times Square |Plaza |1547 |New York |10036 |NY |United States
|40.758001 |-73.985588
|===
----


+*In[147]:*+
[source, ipython3]
----
df28=pd.DataFrame()
df28=df28.append([NY_uni[41:42]]*3,ignore_index=True)
df28=df28.join(swedish_df[['name','categories','location.lat','location.lng']])
df28.head()
----


+*Out[147]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384 |-73.99567
|New York Penn Station |Train Station |40.750356 |-73.992510

|1 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384 |-73.99567
|Grand Central Terminal |Train Station |40.752774 |-73.977180

|2 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384 |-73.99567
|Times Square |Plaza |40.758001 |-73.985588
|===
----

== JOFFREY BALLET SCHOOL


+*In[176]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][43],NY_uni['LONGITUDE'][43], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        joff_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        joff_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[177]:*+
[source, ipython3]
----
joff_df
----


+*Out[177]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |New York Penn Station |Train Station |1832 |New York |10001 |NY
|United States |40.750356 |-73.992510

|1 |Madison Square Garden |Basketball Stadium |1853 |New York |10121 |NY
|United States |40.750752 |-73.993542
|===
----


+*In[179]:*+
[source, ipython3]
----
df29=pd.DataFrame()
df29=df29.append([NY_uni[41:42]]*2,ignore_index=True)
df29=df29.join(joff_df[['name','categories','location.lat','location.lng']])
df29.head()
----


+*Out[179]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384 |-73.99567
|New York Penn Station |Train Station |40.750356 |-73.992510

|1 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384 |-73.99567
|Madison Square Garden |Basketball Stadium |40.750752 |-73.993542
|===
----

== COOPER UNION FOR THE ADVANCEMENT OF SCIENCE


+*In[182]:*+
[source, ipython3]
----
    url = 'https://api.foursquare.com/v2/venues/trending?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,NY_uni['LATITUDE'][45],NY_uni['LONGITUDE'][45], VERSION, RADIUS, LIMIT)

    results = requests.get(url).json()
    if len(results['response']['venues']) == 0:
        trending_venues_df = 'No trending venues are available at the moment!'
    else:
        trending_venues = results['response']['venues']
        trending_venues_df = json_normalize(trending_venues)
        
        # filter columns
        columns_filtered = ['name', 'categories'] + ['location.distance', 'location.city', 'location.postalCode', 'location.state', 'location.country', 'location.lat', 'location.lng']
        cooper_df = trending_venues_df.loc[:, columns_filtered]
        
        # filter the category for each row
        cooper_df['categories'] = trending_venues_df.apply(get_category_type, axis=1)
----


+*In[183]:*+
[source, ipython3]
----
cooper_df
----


+*Out[183]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |name |categories |location.distance |location.city
|location.postalCode |location.state |location.country |location.lat
|location.lng
|0 |Astor Wines & Spirits |Wine Shop |264 |New York |10003 |NY |United
States |40.727984 |-73.993047
|===
----


+*In[184]:*+
[source, ipython3]
----
df30=pd.DataFrame()
df30=df30.append([NY_uni[45:46]]*1,ignore_index=True)
df30=df30.join(joff_df[['name','categories','location.lat','location.lng']])
df30.head()
----


+*Out[184]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AN... |40.72938
|-73.990516 |New York Penn Station |Train Station |40.750356 |-73.99251
|===
----

== Combining The Datasets Into One Dataset


+*In[185]:*+
[source, ipython3]
----
dataset=pd.concat([df,df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30])
dataset.reset_index(drop=True,inplace=True)
dataset
----


+*Out[185]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |name |categories |location.lat
|location.lng
|0 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |Manhattan
Neighborhood Network |TV Station |40.771220 |-73.989250

|1 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |Times
Square |Plaza |40.758001 |-73.985588

|2 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638
|Manhattan Neighborhood Network |TV Station |40.771220 |-73.989250

|3 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638 |Times
Square |Plaza |40.758001 |-73.985588

|4 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434 |New York Penn
Station |Train Station |40.750356 |-73.992510

|... |... |... |... |... |... |... |...

|76 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384
|-73.995670 |Grand Central Terminal |Train Station |40.752774
|-73.977180

|77 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384
|-73.995670 |Times Square |Plaza |40.758001 |-73.985588

|78 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384
|-73.995670 |New York Penn Station |Train Station |40.750356 |-73.992510

|79 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |40.746384
|-73.995670 |Madison Square Garden |Basketball Stadium |40.750752
|-73.993542

|80 |COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AN... |40.729380
|-73.990516 |New York Penn Station |Train Station |40.750356 |-73.992510
|===

81 rows × 7 columns
----

== Downloading the resulting dataframe


+*In[190]:*+
[source, ipython3]
----
from IPython.display import Javascript
js_download = """
var csv = '%s';

var filename = 'dataset.csv';
var blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' });
if (navigator.msSaveBlob) { // IE 10+
    navigator.msSaveBlob(blob, filename);
} else {
    var link = document.createElement("a");
    if (link.download !== undefined) { // feature detection
        // Browsers that support HTML5 download attribute
        var url = URL.createObjectURL(blob);
        link.setAttribute("href", url);
        link.setAttribute("download", filename);
        link.style.visibility = 'hidden';
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
    }
}
""" % dataset.to_csv(index=False).replace('\n','\\n').replace("'","\'")

Javascript(js_download)
----


+*Out[190]:*+
----<IPython.core.display.Javascript object>----


+*In[191]:*+
[source, ipython3]
----
import base64
import pandas as pd
from IPython.display import HTML

def create_download_link( dataset, title = "Download CSV file", filename = "data.csv"):
    csv = dataset.to_csv()
    b64 = base64.b64encode(csv.encode())
    payload = b64.decode()
    html = '<a download="{filename}" href="data:text/csv;base64,{payload}" target="_blank">{title}</a>'
    html = html.format(payload=payload,title=title,filename=filename)
    return HTML(html)


create_download_link(dataset)
----


+*Out[191]:*+
----
data:text/csv;base64,,NAME,LATITUDE,LONGITUDE,name,categories,location.lat,location.lng
0,CARSTEN INSTITUTE OF COSMETOLOGY,40.751893435999996,-73.98027818,Manhattan Neighborhood Network,TV Station,40.77122,-73.98925
1,CARSTEN INSTITUTE OF COSMETOLOGY,40.751893435999996,-73.98027818,Times Square,Plaza,40.75800093119503,-73.98558840233771
2,AMERICAN MUSICAL AND DRAMATIC ACADEMY,40.772309273000104,-73.987638134,Manhattan Neighborhood Network,TV Station,40.77122,-73.98925
3,AMERICAN MUSICAL AND DRAMATIC ACADEMY,40.772309273000104,-73.987638134,Times Square,Plaza,40.75800093119503,-73.98558840233771
4,BERKELEY COLLEGE-NEW YORK,40.75399292,-73.979434125,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
5,BERKELEY COLLEGE-NEW YORK,40.75399292,-73.979434125,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
6,BERKELEY COLLEGE-NEW YORK,40.75399292,-73.979434125,Times Square,Plaza,40.75800093119503,-73.98558840233771
7,CUNY SYSTEM OFFICE,40.7508550000001,-73.97359499999999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
8,CUNY SYSTEM OFFICE,40.7508550000001,-73.97359499999999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
9,CUNY SYSTEM OFFICE,40.7508550000001,-73.97359499999999,Times Square,Plaza,40.75800093119503,-73.98558840233771
10,LIM COLLEGE,40.759786106,-73.97531674,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
11,LIM COLLEGE,40.759786106,-73.97531674,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
12,LIM COLLEGE,40.759786106,-73.97531674,Manhattan Neighborhood Network,TV Station,40.77122,-73.98925
13,LIM COLLEGE,40.759786106,-73.97531674,Times Square,Plaza,40.75800093119503,-73.98558840233771
14,THE NEW SCHOOL,40.7354980000001,-73.997158,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
15,MANHATTAN INSTITUTE,40.754262,-73.97734399999999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
16,MANHATTAN INSTITUTE,40.754262,-73.97734399999999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
17,MANHATTAN INSTITUTE,40.754262,-73.97734399999999,Times Square,Plaza,40.75800093119503,-73.98558840233771
18,MANHATTAN INSTITUTE,40.754262,-73.97734399999999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
19,MANHATTAN INSTITUTE,40.754262,-73.97734399999999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
20,MANHATTAN INSTITUTE,40.754262,-73.97734399999999,Times Square,Plaza,40.75800093119503,-73.98558840233771
21,INSTITUTE OF CULINARY EDUCATION,40.712988405,-74.01515684600001,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
22,INSTITUTE OF CULINARY EDUCATION,40.712988405,-74.01515684600001,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
23,INSTITUTE OF CULINARY EDUCATION,40.712988405,-74.01515684600001,Times Square,Plaza,40.75800093119503,-73.98558840233771
24,FOCUS PERSONAL TRAINING INSTITUTE,40.7458800000001,-73.9917809999999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
25,FOCUS PERSONAL TRAINING INSTITUTE,40.7458800000001,-73.9917809999999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
26,FOCUS PERSONAL TRAINING INSTITUTE,40.7458800000001,-73.9917809999999,Times Square,Plaza,40.75800093119503,-73.98558840233771
27,THE ART INSTITUTE OF NEW YORK CITY,40.7550420000001,-73.989177,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
28,THE ART INSTITUTE OF NEW YORK CITY,40.7550420000001,-73.989177,Times Square,Plaza,40.75800093119503,-73.98558840233771
29,THE ART INSTITUTE OF NEW YORK CITY,40.7550420000001,-73.989177,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
30,THE ART INSTITUTE OF NEW YORK CITY,40.7550420000001,-73.989177,Manhattan Neighborhood Network,TV Station,40.77122,-73.98925
31,NEW AGE TRAINING,40.748277638000005,-73.991509997,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
32,NEW AGE TRAINING,40.748277638000005,-73.991509997,Times Square,Plaza,40.75800093119503,-73.98558840233771
33,NEW AGE TRAINING,40.748277638000005,-73.991509997,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
34,THE JUILLIARD SCHOOL,40.7737250000001,-73.98291299999991,Times Square,Plaza,40.75800093119503,-73.98558840233771
35,THE AILEY SCHOOL,40.766920526999996,-73.986890762,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
36,THE AILEY SCHOOL,40.766920526999996,-73.986890762,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
37,THE AILEY SCHOOL,40.766920526999996,-73.986890762,Times Square,Plaza,40.75800093119503,-73.98558840233771
38,CUNY BERNARD M BARUCH COLLEGE,40.740238214,-73.98341700899991,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
39,CUNY BERNARD M BARUCH COLLEGE,40.740238214,-73.98341700899991,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
40,CUNY BERNARD M BARUCH COLLEGE,40.740238214,-73.98341700899991,Times Square,Plaza,40.75800093119503,-73.98558840233771
41,MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH,40.764350805999996,-73.9837491219999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
42,MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH,40.764350805999996,-73.9837491219999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
43,MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH,40.764350805999996,-73.9837491219999,Times Square,Plaza,40.75800093119503,-73.98558840233771
44,EMPIRE BEAUTY SCHOOL-MANHATTAN,40.748937556,-73.986453228,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
45,EMPIRE BEAUTY SCHOOL-MANHATTAN,40.748937556,-73.986453228,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
46,EMPIRE BEAUTY SCHOOL-MANHATTAN,40.748937556,-73.986453228,Times Square,Plaza,40.75800093119503,-73.98558840233771
47,EMPIRE BEAUTY SCHOOL-MANHATTAN,40.748937556,-73.986453228,Trader Joe's,Grocery Store,40.741739139805574,-73.99365296900864
48,SOTHEBY'S INSTITUTE OF ART-NY,40.7563991660001,-73.97258750399999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
49,SOTHEBY'S INSTITUTE OF ART-NY,40.7563991660001,-73.97258750399999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
50,SOTHEBY'S INSTITUTE OF ART-NY,40.7563991660001,-73.97258750399999,Times Square,Plaza,40.75800093119503,-73.98558840233771
51,"CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHETICS, SKIN CARE & MAKEUP",40.744988434,-73.9865565659999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
52,"CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHETICS, SKIN CARE & MAKEUP",40.744988434,-73.9865565659999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
53,"CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHETICS, SKIN CARE & MAKEUP",40.744988434,-73.9865565659999,Times Square,Plaza,40.75800093119503,-73.98558840233771
54,RELAY GRADUATE SCHOOL OF EDUCATION,40.740509192,-73.993410758,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
55,RELAY GRADUATE SCHOOL OF EDUCATION,40.740509192,-73.993410758,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
56,DEVRY COLLEGE OF NEW YORK,40.747654088000004,-73.983468252,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
57,DEVRY COLLEGE OF NEW YORK,40.747654088000004,-73.983468252,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
58,DEVRY COLLEGE OF NEW YORK,40.747654088000004,-73.983468252,Times Square,Plaza,40.75800093119503,-73.98558840233771
59,CULINARY TECH CENTER,40.7541746850001,-73.998972329,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
60,CULINARY TECH CENTER,40.7541746850001,-73.998972329,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
61,CULINARY TECH CENTER,40.7541746850001,-73.998972329,Times Square,Plaza,40.75800093119503,-73.98558840233771
62,CULINARY TECH CENTER,40.7541746850001,-73.998972329,Google New York,Office,40.7416158042599,-74.00390625
63,ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS,40.7429867070001,-73.984860431,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
64,ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS,40.7429867070001,-73.984860431,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
65,ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS,40.7429867070001,-73.984860431,Times Square,Plaza,40.75800093119503,-73.98558840233771
66,CUNY HUNTER COLLEGE,40.768668744,-73.96479536,Central Park,Park,40.78408342593807,-73.96485328674316
67,TRI-STATE COLLEGE OF ACUPUNCTURE,40.7398617640001,-74.00208524199999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
68,AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNERAL SERVICE,40.769030688,-73.993782375,Times Square,Plaza,40.75800093119503,-73.98558840233771
69,GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK,40.7513509510001,-73.9806474649999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
70,GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK,40.7513509510001,-73.9806474649999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
71,GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK,40.7513509510001,-73.9806474649999,Times Square,Plaza,40.75800093119503,-73.98558840233771
72,NEW YORK UNIVERSITY,40.729451904,-73.997263897,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
73,NEW YORK UNIVERSITY,40.729451904,-73.997263897,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
74,NEW YORK UNIVERSITY,40.729451904,-73.997263897,Times Square,Plaza,40.75800093119503,-73.98558840233771
75,SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES,40.7463842550001,-73.99567003199999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
76,SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES,40.7463842550001,-73.99567003199999,Grand Central Terminal,Train Station,40.75277448758534,-73.977180482729
77,SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES,40.7463842550001,-73.99567003199999,Times Square,Plaza,40.75800093119503,-73.98558840233771
78,SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES,40.7463842550001,-73.99567003199999,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
79,SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES,40.7463842550001,-73.99567003199999,Madison Square Garden,Basketball Stadium,40.75075196505169,-73.99354219436646
80,COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AND ART,40.7293798200001,-73.99051616299991,New York Penn Station,Train Station,40.75035589563138,-73.99250959441304
[Download
CSV file]
----

== Explority Data Analysis


+*In[55]:*+
[source, ipython3]
----
df_data_0=pd.read_csv('new_data.csv')
----


+*In[56]:*+
[source, ipython3]
----
df_data_0.rename(columns={'NAME':'university','LATITUDE':'uni_lat','LONGITUDE':'uni_lng','name':'venue','location.lat':'venue_lat','location.lng':'venue_lng'},inplace=True)
----


+*In[57]:*+
[source, ipython3]
----
df_data_0.drop(columns='Unnamed: 0',inplace=True)
----

The number of the venues category


+*In[58]:*+
[source, ipython3]
----
print('There are {} uniques categories.'.format(len(df_data_0['categories'].unique())))
----


+*Out[58]:*+
----
There are 7 uniques categories.
----

Making a data frame showing the names of the categories and how many
venues are there and using it later for the visualization


+*In[59]:*+
[source, ipython3]
----
grouped_by_categories=df_data_0.groupby('categories')['venue'].count()
grouped_by_categories=grouped_by_categories.to_frame()
grouped_by_categories
----


+*Out[59]:*+
----
venue

categories

Basketball Stadium

1

Grocery Store

1

Office

1

Park

1

Plaza

25

TV Station

4

Train Station

48
----

bar chart represent the categories and how many venues in each category


+*In[60]:*+
[source, ipython3]
----

ax = grouped_by_categories.plot.bar(y='venue',label=True)
ax
plt.title('Venues Catergories and their Frequency')
plt.ylabel('Frequency')

----


+*Out[60]:*+
----Text(0, 0.5, 'Frequency')
![png](output_160_1.png)
----

And the pie chart to represent the categories of the venues by
percentages


+*In[61]:*+
[source, ipython3]
----
fig = plt.figure()
fig.set_figheight(5)
fig.set_figwidth(8)
x=np.char.array(['Basketball Stadium','Grocery Store','Office','Park','Plaza','TV Station','Train Station'])
y= np.array([1,1,1,1,25,4,48])
patches, texts = plt.pie(y, startangle=90, radius=1.2)
porcent = 100.*y/y.sum()
labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]

sort_legend = True
if sort_legend:
    patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),
                                          key=lambda x: x[2],
                                          reverse=True))

plt.legend(patches, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')
----


+*Out[61]:*+
----
/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:17: MatplotlibDeprecationWarning: Unrecognized location 'left center'. Falling back on 'best'; valid locations are
	best
	upper right
	upper left
	lower left
	lower right
	right
	center left
	center right
	lower center
	upper center
	center
This will raise an exception in 3.3.

![png](output_162_1.png)
----

== Analyzing The Dataset


+*In[62]:*+
[source, ipython3]
----
# one hot encoding
university_onehot = pd.get_dummies(df_data_0[['categories']], prefix="", prefix_sep="")

# add neighborhood column back to dataframe
university_onehot['university'] = df_data_0['university'] 

# move neighborhood column to the first column
fixed_columns = [university_onehot.columns[-1]] + list(university_onehot.columns[:-1])
university_onehot = university_onehot[fixed_columns]

university_onehot.head()
----


+*Out[62]:*+
----
[cols=",,,,,,,,",options="header",]
|===
| |university |Basketball Stadium |Grocery Store |Office |Park |Plaza
|TV Station |Train Station
|0 |CARSTEN INSTITUTE OF COSMETOLOGY |0 |0 |0 |0 |0 |1 |0

|1 |CARSTEN INSTITUTE OF COSMETOLOGY |0 |0 |0 |0 |1 |0 |0

|2 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |0 |0 |0 |0 |0 |1 |0

|3 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |0 |0 |0 |0 |1 |0 |0

|4 |BERKELEY COLLEGE-NEW YORK |0 |0 |0 |0 |0 |0 |1
|===
----

== grouping the rows by university and by taking the mean of the frequency of occurrence of each category


+*In[63]:*+
[source, ipython3]
----
uni_grouped = university_onehot.groupby('university').mean().reset_index()
uni_grouped
----


+*Out[63]:*+
----
[cols=",,,,,,,,",options="header",]
|===
| |university |Basketball Stadium |Grocery Store |Office |Park |Plaza
|TV Station |Train Station
|0 |AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNER... |0.0 |0.00 |0.00
|0.0 |1.000000 |0.00 |0.000000

|1 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |0.0 |0.00 |0.00 |0.0
|0.500000 |0.50 |0.000000

|2 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |0.0 |0.00 |0.00 |0.0
|0.333333 |0.00 |0.666667

|3 |BERKELEY COLLEGE-NEW YORK |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00
|0.666667

|4 |CARSTEN INSTITUTE OF COSMETOLOGY |0.0 |0.00 |0.00 |0.0 |0.500000
|0.50 |0.000000

|5 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |0.0 |0.00 |0.00
|0.0 |0.333333 |0.00 |0.666667

|6 |COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AN... |0.0 |0.00 |0.00
|0.0 |0.000000 |0.00 |1.000000

|7 |CULINARY TECH CENTER |0.0 |0.00 |0.25 |0.0 |0.250000 |0.00 |0.500000

|8 |CUNY BERNARD M BARUCH COLLEGE |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00
|0.666667

|9 |CUNY HUNTER COLLEGE |0.0 |0.00 |0.00 |1.0 |0.000000 |0.00 |0.000000

|10 |CUNY SYSTEM OFFICE |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00 |0.666667

|11 |DEVRY COLLEGE OF NEW YORK |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00
|0.666667

|12 |EMPIRE BEAUTY SCHOOL-MANHATTAN |0.0 |0.25 |0.00 |0.0 |0.250000
|0.00 |0.500000

|13 |FOCUS PERSONAL TRAINING INSTITUTE |0.0 |0.00 |0.00 |0.0 |0.333333
|0.00 |0.666667

|14 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |0.0 |0.00 |0.00 |0.0
|0.333333 |0.00 |0.666667

|15 |INSTITUTE OF CULINARY EDUCATION |0.0 |0.00 |0.00 |0.0 |0.333333
|0.00 |0.666667

|16 |LIM COLLEGE |0.0 |0.00 |0.00 |0.0 |0.250000 |0.25 |0.500000

|17 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |0.0 |0.00 |0.00 |0.0
|0.333333 |0.00 |0.666667

|18 |MANHATTAN INSTITUTE |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00 |0.666667

|19 |NEW AGE TRAINING |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00 |0.666667

|20 |NEW YORK UNIVERSITY |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00 |0.666667

|21 |RELAY GRADUATE SCHOOL OF EDUCATION |0.0 |0.00 |0.00 |0.0 |0.000000
|0.00 |1.000000

|22 |SOTHEBY'S INSTITUTE OF ART-NY |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00
|0.666667

|23 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |0.2 |0.00 |0.00
|0.0 |0.200000 |0.00 |0.600000

|24 |THE AILEY SCHOOL |0.0 |0.00 |0.00 |0.0 |0.333333 |0.00 |0.666667

|25 |THE ART INSTITUTE OF NEW YORK CITY |0.0 |0.00 |0.00 |0.0 |0.250000
|0.25 |0.500000

|26 |THE JUILLIARD SCHOOL |0.0 |0.00 |0.00 |0.0 |1.000000 |0.00
|0.000000

|27 |THE NEW SCHOOL |0.0 |0.00 |0.00 |0.0 |0.000000 |0.00 |1.000000

|28 |TRI-STATE COLLEGE OF ACUPUNCTURE |0.0 |0.00 |0.00 |0.0 |0.000000
|0.00 |1.000000
|===
----

== Let’s print each university along with the top 3 most common venues


+*In[64]:*+
[source, ipython3]
----
num_top_venues = 3

for university in uni_grouped['university']:
    print("----"+university+"----")
    temp = uni_grouped[uni_grouped['university'] == university].T.reset_index()
    temp.columns = ['venue','freq']
    temp = temp.iloc[1:]
    temp['freq'] = temp['freq'].astype(float)
    temp = temp.round({'freq': 2})
    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))
    print('\n')
----


+*Out[64]:*+
----
----AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNERAL SERVICE----
                venue  freq
0               Plaza   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----AMERICAN MUSICAL AND DRAMATIC ACADEMY----
                venue  freq
0               Plaza   0.5
1          TV Station   0.5
2  Basketball Stadium   0.0


----ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----BERKELEY COLLEGE-NEW YORK----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----CARSTEN INSTITUTE OF COSMETOLOGY----
                venue  freq
0               Plaza   0.5
1          TV Station   0.5
2  Basketball Stadium   0.0


----CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHETICS, SKIN CARE & MAKEUP----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AND ART----
                venue  freq
0       Train Station   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----CULINARY TECH CENTER----
           venue  freq
0  Train Station  0.50
1         Office  0.25
2          Plaza  0.25


----CUNY BERNARD M BARUCH COLLEGE----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----CUNY HUNTER COLLEGE----
                venue  freq
0                Park   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----CUNY SYSTEM OFFICE----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----DEVRY COLLEGE OF NEW YORK----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----EMPIRE BEAUTY SCHOOL-MANHATTAN----
           venue  freq
0  Train Station  0.50
1  Grocery Store  0.25
2          Plaza  0.25


----FOCUS PERSONAL TRAINING INSTITUTE----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----INSTITUTE OF CULINARY EDUCATION----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----LIM COLLEGE----
           venue  freq
0  Train Station  0.50
1          Plaza  0.25
2     TV Station  0.25


----MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----MANHATTAN INSTITUTE----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----NEW AGE TRAINING----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----NEW YORK UNIVERSITY----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----RELAY GRADUATE SCHOOL OF EDUCATION----
                venue  freq
0       Train Station   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----SOTHEBY'S INSTITUTE OF ART-NY----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES----
                venue  freq
0       Train Station   0.6
1  Basketball Stadium   0.2
2               Plaza   0.2


----THE AILEY SCHOOL----
                venue  freq
0       Train Station  0.67
1               Plaza  0.33
2  Basketball Stadium  0.00


----THE ART INSTITUTE OF NEW YORK CITY----
           venue  freq
0  Train Station  0.50
1          Plaza  0.25
2     TV Station  0.25


----THE JUILLIARD SCHOOL----
                venue  freq
0               Plaza   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----THE NEW SCHOOL----
                venue  freq
0       Train Station   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----TRI-STATE COLLEGE OF ACUPUNCTURE----
                venue  freq
0       Train Station   1.0
1  Basketball Stadium   0.0
2       Grocery Store   0.0


----

Making a Dataframe for that


+*In[65]:*+
[source, ipython3]
----
def return_most_common_venues(row, num_top_venues):
    row_categories = row.iloc[1:]
    row_categories_sorted = row_categories.sort_values(ascending=False)
    
    return row_categories_sorted.index.values[0:num_top_venues]
----


+*In[66]:*+
[source, ipython3]
----
num_top_venues = 3

indicators = ['st', 'nd', 'rd']

# create columns according to number of top venues
columns = ['university']
for ind in np.arange(num_top_venues):
    try:
        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))
    except:
        columns.append('{}th Most Common Venue'.format(ind+1))

# create a new dataframe
universities_venues_sorted = pd.DataFrame(columns=columns)
universities_venues_sorted['university'] = uni_grouped['university']

for ind in np.arange(uni_grouped.shape[0]):
    universities_venues_sorted.iloc[ind, 1:] = return_most_common_venues(uni_grouped.iloc[ind, :], num_top_venues)

universities_venues_sorted
----


+*Out[66]:*+
----
[cols=",,,,",options="header",]
|===
| |university |1st Most Common Venue |2nd Most Common Venue |3rd Most
Common Venue
|0 |AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNER... |Plaza |Train
Station |TV Station

|1 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |TV Station |Plaza |Train
Station

|2 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |Train Station |Plaza |TV
Station

|3 |BERKELEY COLLEGE-NEW YORK |Train Station |Plaza |TV Station

|4 |CARSTEN INSTITUTE OF COSMETOLOGY |TV Station |Plaza |Train Station

|5 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |Train Station
|Plaza |TV Station

|6 |COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AN... |Train Station |TV
Station |Plaza

|7 |CULINARY TECH CENTER |Train Station |Plaza |Office

|8 |CUNY BERNARD M BARUCH COLLEGE |Train Station |Plaza |TV Station

|9 |CUNY HUNTER COLLEGE |Park |Train Station |TV Station

|10 |CUNY SYSTEM OFFICE |Train Station |Plaza |TV Station

|11 |DEVRY COLLEGE OF NEW YORK |Train Station |Plaza |TV Station

|12 |EMPIRE BEAUTY SCHOOL-MANHATTAN |Train Station |Plaza |Grocery Store

|13 |FOCUS PERSONAL TRAINING INSTITUTE |Train Station |Plaza |TV Station

|14 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |Train Station |Plaza |TV
Station

|15 |INSTITUTE OF CULINARY EDUCATION |Train Station |Plaza |TV Station

|16 |LIM COLLEGE |Train Station |TV Station |Plaza

|17 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |Train Station |Plaza |TV
Station

|18 |MANHATTAN INSTITUTE |Train Station |Plaza |TV Station

|19 |NEW AGE TRAINING |Train Station |Plaza |TV Station

|20 |NEW YORK UNIVERSITY |Train Station |Plaza |TV Station

|21 |RELAY GRADUATE SCHOOL OF EDUCATION |Train Station |TV Station
|Plaza

|22 |SOTHEBY'S INSTITUTE OF ART-NY |Train Station |Plaza |TV Station

|23 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |Train Station
|Plaza |Basketball Stadium

|24 |THE AILEY SCHOOL |Train Station |Plaza |TV Station

|25 |THE ART INSTITUTE OF NEW YORK CITY |Train Station |TV Station
|Plaza

|26 |THE JUILLIARD SCHOOL |Plaza |Train Station |TV Station

|27 |THE NEW SCHOOL |Train Station |TV Station |Plaza

|28 |TRI-STATE COLLEGE OF ACUPUNCTURE |Train Station |TV Station |Plaza
|===
----

== Cluster The Universities

== Finding the optimal number of clusters


+*In[67]:*+
[source, ipython3]
----
uni_grouped_clustering = uni_grouped.drop('university', 1)
Sum_of_squared_distances = []
K = range(1,8)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(uni_grouped_clustering)
    Sum_of_squared_distances.append(km.inertia_)
----


+*In[68]:*+
[source, ipython3]
----
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
----


+*Out[68]:*+
----
![png](output_175_0.png)
----


+*In[69]:*+
[source, ipython3]
----

# set number of clusters
kclusters = 4
# run k-means clustering
kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(uni_grouped_clustering)

# check cluster labels generated for each row in the dataframe
kmeans.labels_[0:10] 
----


+*Out[69]:*+
----array([1, 1, 2, 2, 1, 2, 0, 2, 2, 3], dtype=int32)----

== The clustered universities based on the common characteristics of the trending venues


+*In[70]:*+
[source, ipython3]
----
universities_venues_sorted.head()
----


+*Out[70]:*+
----
[cols=",,,,",options="header",]
|===
| |university |1st Most Common Venue |2nd Most Common Venue |3rd Most
Common Venue
|0 |AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNER... |Plaza |Train
Station |TV Station

|1 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |TV Station |Plaza |Train
Station

|2 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |Train Station |Plaza |TV
Station

|3 |BERKELEY COLLEGE-NEW YORK |Train Station |Plaza |TV Station

|4 |CARSTEN INSTITUTE OF COSMETOLOGY |TV Station |Plaza |Train Station
|===
----


+*In[71]:*+
[source, ipython3]
----
# add clustering labels
universities_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)

data_merged = NY_uni

# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood
data_merged = data_merged.join(universities_venues_sorted.set_index('university'), on='NAME')

data_merged.head() # check the last columns!
----


+*Out[71]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |Cluster Labels |1st Most Common Venue |2nd
Most Common Venue |3rd Most Common Venue
|0 |MESIVTHA TIFERETH JERUSALEM OF AMERICA |40.713812 |-73.991271 |NaN
|NaN |NaN |NaN

|1 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |1.0 |TV
Station |Plaza |Train Station

|2 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638 |1.0
|TV Station |Plaza |Train Station

|3 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434 |2.0 |Train Station
|Plaza |TV Station

|4 |CUNY SYSTEM OFFICE |40.750855 |-73.973595 |2.0 |Train Station |Plaza
|TV Station
|===
----


+*In[72]:*+
[source, ipython3]
----
data_merged.fillna( method ='ffill', inplace = True) 
data_merged.drop(0,inplace=True)
data_merged.reset_index(drop=True,inplace=True)
data_merged['Cluster Labels'] =data_merged['Cluster Labels'].astype(int)
data_merged.head()
----


+*Out[72]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |NAME |LATITUDE |LONGITUDE |Cluster Labels |1st Most Common Venue |2nd
Most Common Venue |3rd Most Common Venue
|0 |CARSTEN INSTITUTE OF COSMETOLOGY |40.751893 |-73.980278 |1 |TV
Station |Plaza |Train Station

|1 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |40.772309 |-73.987638 |1 |TV
Station |Plaza |Train Station

|2 |BERKELEY COLLEGE-NEW YORK |40.753993 |-73.979434 |2 |Train Station
|Plaza |TV Station

|3 |CUNY SYSTEM OFFICE |40.750855 |-73.973595 |2 |Train Station |Plaza
|TV Station

|4 |METROPOLITAN COLLEGE OF NEW YORK |40.708592 |-74.014677 |2 |Train
Station |Plaza |TV Station
|===
----


+*In[73]:*+
[source, ipython3]
----
universities_venues_sorted
----


+*Out[73]:*+
----
[cols=",,,,,",options="header",]
|===
| |Cluster Labels |university |1st Most Common Venue |2nd Most Common
Venue |3rd Most Common Venue
|0 |1 |AMERICAN ACADEMY MCALLISTER INSTITUTE OF FUNER... |Plaza |Train
Station |TV Station

|1 |1 |AMERICAN MUSICAL AND DRAMATIC ACADEMY |TV Station |Plaza |Train
Station

|2 |2 |ATELIER ESTHETIQUE INSTITUTE OF ESTHETICS |Train Station |Plaza
|TV Station

|3 |2 |BERKELEY COLLEGE-NEW YORK |Train Station |Plaza |TV Station

|4 |1 |CARSTEN INSTITUTE OF COSMETOLOGY |TV Station |Plaza |Train
Station

|5 |2 |CHRISTINE VALMY INTERNATIONAL SCHOOL FOR ESTHE... |Train Station
|Plaza |TV Station

|6 |0 |COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AN... |Train Station
|TV Station |Plaza

|7 |2 |CULINARY TECH CENTER |Train Station |Plaza |Office

|8 |2 |CUNY BERNARD M BARUCH COLLEGE |Train Station |Plaza |TV Station

|9 |3 |CUNY HUNTER COLLEGE |Park |Train Station |TV Station

|10 |2 |CUNY SYSTEM OFFICE |Train Station |Plaza |TV Station

|11 |2 |DEVRY COLLEGE OF NEW YORK |Train Station |Plaza |TV Station

|12 |2 |EMPIRE BEAUTY SCHOOL-MANHATTAN |Train Station |Plaza |Grocery
Store

|13 |2 |FOCUS PERSONAL TRAINING INSTITUTE |Train Station |Plaza |TV
Station

|14 |2 |GEMOLOGICAL INSTITUTE OF AMERICA-NEW YORK |Train Station |Plaza
|TV Station

|15 |2 |INSTITUTE OF CULINARY EDUCATION |Train Station |Plaza |TV
Station

|16 |2 |LIM COLLEGE |Train Station |TV Station |Plaza

|17 |2 |MANDL SCHOOL-THE COLLEGE OF ALLIED HEALTH |Train Station |Plaza
|TV Station

|18 |2 |MANHATTAN INSTITUTE |Train Station |Plaza |TV Station

|19 |2 |NEW AGE TRAINING |Train Station |Plaza |TV Station

|20 |2 |NEW YORK UNIVERSITY |Train Station |Plaza |TV Station

|21 |0 |RELAY GRADUATE SCHOOL OF EDUCATION |Train Station |TV Station
|Plaza

|22 |2 |SOTHEBY'S INSTITUTE OF ART-NY |Train Station |Plaza |TV Station

|23 |2 |SWEDISH INSTITUTE A COLLEGE OF HEALTH SCIENCES |Train Station
|Plaza |Basketball Stadium

|24 |2 |THE AILEY SCHOOL |Train Station |Plaza |TV Station

|25 |2 |THE ART INSTITUTE OF NEW YORK CITY |Train Station |TV Station
|Plaza

|26 |1 |THE JUILLIARD SCHOOL |Plaza |Train Station |TV Station

|27 |0 |THE NEW SCHOOL |Train Station |TV Station |Plaza

|28 |0 |TRI-STATE COLLEGE OF ACUPUNCTURE |Train Station |TV Station
|Plaza
|===
----

== Map of the clustered universities based on the common characteristics of the trending venues


+*In[74]:*+
[source, ipython3]
----
# create map
map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)

# set color scheme for the clusters
x = np.arange(kclusters)
ys = [i + x + (i*x)**2 for i in range(kclusters)]
colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))
rainbow = [colors.rgb2hex(i) for i in colors_array]

# add markers to the map
markers_colors = []
for lat, lon, poi, cluster in zip(data_merged['LATITUDE'], data_merged['LONGITUDE'], data_merged['NAME'], data_merged['Cluster Labels']):
    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)
    folium.CircleMarker(
        [lat, lon],
        radius=5,
        popup=label,
        color=rainbow[cluster-1],
        fill=True,
        fill_color=rainbow[cluster-1],
        fill_opacity=0.7).add_to(map_clusters)
       
map_clusters
----


+*Out[74]:*+
----

----


+*In[ ]:*+
[source, ipython3]
----

----


+*In[ ]:*+
[source, ipython3]
----

----
